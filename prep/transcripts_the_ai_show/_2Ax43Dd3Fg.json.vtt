[
    {
        "text": ">> You're not going to want to miss this episode of the AI show.",
        "start": 0.0,
        "duration": 2.64
    },
    {
        "text": "We talk all about generating",
        "start": 2.64,
        "duration": 1.48
    },
    {
        "text": "the right answers with Azure AI search.",
        "start": 4.12,
        "duration": 3.04
    },
    {
        "text": "What's new since Microsoft Ignite make sure you tune in.",
        "start": 7.16,
        "duration": 2.53
    },
    {
        "text": "[MUSIC] Hello and welcome to this episode of the AI show.",
        "start": 9.69,
        "duration": 9.07
    },
    {
        "text": "We're talking all about generating the right answers",
        "start": 18.76,
        "duration": 2.74
    },
    {
        "text": "with Azure AI search with my friend Farzad.",
        "start": 21.5,
        "duration": 3.74
    },
    {
        "text": "How are you doing my friend?",
        "start": 25.24,
        "duration": 2.155
    },
    {
        "text": ">> I'm doing well. I'm really excited for today.",
        "start": 27.395,
        "duration": 2.81
    },
    {
        "text": ">> Fantastic. Tell us who you are and what you do.",
        "start": 30.205,
        "duration": 2.3
    },
    {
        "text": ">> Yeah, my name is Farzad Sunavala.",
        "start": 32.505,
        "duration": 2.195
    },
    {
        "text": "I am a Product Manager on Azure AI Search,",
        "start": 34.7,
        "duration": 3.22
    },
    {
        "text": "formerly known as Azure Cognitive Search.",
        "start": 37.92,
        "duration": 2.2
    },
    {
        "text": ">> Oh, so things have changed since Microsoft Ignite.",
        "start": 40.12,
        "duration": 4.42
    },
    {
        "text": "Can you fill us in on some of those details?",
        "start": 44.54,
        "duration": 2.645
    },
    {
        "text": ">> Since Microsoft Ignite,",
        "start": 47.185,
        "duration": 1.795
    },
    {
        "text": "we're pleased to announce that we have a new name for our product.",
        "start": 48.98,
        "duration": 3.595
    },
    {
        "text": "Formerly known as Azure Cognitive Search,",
        "start": 52.575,
        "duration": 2.445
    },
    {
        "text": "we are now Azure AI Search.",
        "start": 55.02,
        "duration": 2.735
    },
    {
        "text": "I know. Fancy, right?",
        "start": 57.755,
        "duration": 2.2
    },
    {
        "text": ">> Yeah.",
        "start": 59.955,
        "duration": 0.99
    },
    {
        "text": ">> Another name change that we have is",
        "start": 60.945,
        "duration": 2.915
    },
    {
        "text": "we previously had a feature in",
        "start": 63.86,
        "duration": 2.58
    },
    {
        "text": "Azure AI search called Semantic Search and we",
        "start": 66.44,
        "duration": 2.72
    },
    {
        "text": "are now calling that Semantic Ranker.",
        "start": 69.16,
        "duration": 3.235
    },
    {
        "text": ">> Yeah, and I like this because if I",
        "start": 72.395,
        "duration": 2.605
    },
    {
        "text": "remember right when we talked",
        "start": 75.0,
        "duration": 1.16
    },
    {
        "text": "earlier with Liam a couple of weeks ago,",
        "start": 76.16,
        "duration": 2.32
    },
    {
        "text": "the semantic search, what it actually did is it took",
        "start": 78.48,
        "duration": 2.72
    },
    {
        "text": "the keyword search and",
        "start": 81.2,
        "duration": 1.72
    },
    {
        "text": "the vector search and then it re-ranked those things.",
        "start": 82.92,
        "duration": 3.22
    },
    {
        "text": "Ranking makes more sense to me. Am I getting this right?",
        "start": 86.14,
        "duration": 2.74
    },
    {
        "text": ">> Yeah, 100 percent, correct.",
        "start": 88.88,
        "duration": 1.825
    },
    {
        "text": "We know that vector search alone,",
        "start": 90.705,
        "duration": 2.055
    },
    {
        "text": "it's good, but it's not the best possible retrieval mode.",
        "start": 92.76,
        "duration": 2.72
    },
    {
        "text": "We have hybrid search, which is even better,",
        "start": 95.48,
        "duration": 2.0
    },
    {
        "text": "but hybrid search with semantic ranking on",
        "start": 97.48,
        "duration": 2.84
    },
    {
        "text": "top to get that best possible precision and ordered ranking.",
        "start": 100.32,
        "duration": 3.38
    },
    {
        "text": "That's what you want to go for and we're pleased",
        "start": 103.7,
        "duration": 1.88
    },
    {
        "text": "to announce that in Azure AI search.",
        "start": 105.58,
        "duration": 2.235
    },
    {
        "text": ">> Amazing. Were there any other announcements",
        "start": 107.815,
        "duration": 2.265
    },
    {
        "text": "that you could just sort of rattle off to us?",
        "start": 110.08,
        "duration": 2.435
    },
    {
        "text": ">> Yeah, let's talk about it.",
        "start": 112.515,
        "duration": 2.475
    },
    {
        "text": "Talk about Azure I Search,",
        "start": 114.99,
        "duration": 2.3
    },
    {
        "text": "Vector Search, and Semantic Ranker.",
        "start": 117.29,
        "duration": 2.04
    },
    {
        "text": "We're pleased to announce that at Microsoft Ignite,",
        "start": 119.33,
        "duration": 3.18
    },
    {
        "text": "we announced the general availability of vector search.",
        "start": 122.51,
        "duration": 2.82
    },
    {
        "text": "We're ready to support you.",
        "start": 125.33,
        "duration": 2.08
    },
    {
        "text": "Go use it in your production-ready applications.",
        "start": 127.41,
        "duration": 2.795
    },
    {
        "text": "We're really excited to",
        "start": 130.205,
        "duration": 2.305
    },
    {
        "text": "see a bunch of your usage with vector search,",
        "start": 132.51,
        "duration": 2.9
    },
    {
        "text": "hybrid search, and so on.",
        "start": 135.41,
        "duration": 1.975
    },
    {
        "text": "Additionally, we had another public preview announcement",
        "start": 137.385,
        "duration": 4.235
    },
    {
        "text": "at Microsoft Ignite and so we have",
        "start": 141.62,
        "duration": 2.32
    },
    {
        "text": "a new feature that I'll dive into in a bit called",
        "start": 143.94,
        "duration": 3.08
    },
    {
        "text": "Integrated Vectorization and so talk about end-to-end ingestion.",
        "start": 147.02,
        "duration": 4.63
    },
    {
        "text": "I think this is a cool really feature.",
        "start": 151.65,
        "duration": 1.92
    },
    {
        "text": "I'm excited to show today",
        "start": 153.57,
        "duration": 2.39
    },
    {
        "text": "to really make the whole rag pattern process.",
        "start": 155.96,
        "duration": 2.74
    },
    {
        "text": "I'm using Azure AI search, chunking,",
        "start": 158.7,
        "duration": 2.1
    },
    {
        "text": "vectorization a whole bunch easier.",
        "start": 160.8,
        "duration": 2.72
    },
    {
        "text": "Then lastly, we also have generally available the semantic ranker.",
        "start": 163.52,
        "duration": 4.54
    },
    {
        "text": "It's been in preview for a while but now it's GA, go use it.",
        "start": 168.06,
        "duration": 4.44
    },
    {
        "text": "Get that best possible retrieval in Azure AI search.",
        "start": 172.5,
        "duration": 3.57
    },
    {
        "text": ">> That's awesome. This is all good stuff.",
        "start": 176.07,
        "duration": 1.87
    },
    {
        "text": "But oh, and there you go. There's the slide.",
        "start": 177.94,
        "duration": 1.46
    },
    {
        "text": "Because Liam, he foretold,",
        "start": 179.4,
        "duration": 1.8
    },
    {
        "text": "he's like you should watch for another announcement regarding",
        "start": 181.2,
        "duration": 3.36
    },
    {
        "text": "perhaps pricing and this",
        "start": 184.56,
        "duration": 1.62
    },
    {
        "text": "is the pricing announcement. Can you tell us about that?",
        "start": 186.18,
        "duration": 2.18
    },
    {
        "text": ">> Yeah, this is the really exciting piece of",
        "start": 188.36,
        "duration": 2.4
    },
    {
        "text": "the semantic ranker which is now GA. As we know,",
        "start": 190.76,
        "duration": 3.2
    },
    {
        "text": "hybrid plus semantic re-ranking",
        "start": 193.96,
        "duration": 2.89
    },
    {
        "text": "is the best possible retrieval mode.",
        "start": 196.85,
        "duration": 1.61
    },
    {
        "text": "We want all of you to leverage it for",
        "start": 198.46,
        "duration": 1.54
    },
    {
        "text": "your generative AI applications and so we made",
        "start": 200.0,
        "duration": 3.06
    },
    {
        "text": "significant changes to our business model and so it's",
        "start": 203.06,
        "duration": 2.66
    },
    {
        "text": "going to be a lot more economical now than it was in preview.",
        "start": 205.72,
        "duration": 3.165
    },
    {
        "text": "You get a 3,000 requests per month and then additionally,",
        "start": 208.885,
        "duration": 3.655
    },
    {
        "text": "it's only $1 per 1,000 requests thereafter.",
        "start": 212.54,
        "duration": 3.22
    },
    {
        "text": "Big, big changes to the business model.",
        "start": 215.76,
        "duration": 2.52
    },
    {
        "text": "A lot more economical for you to use.",
        "start": 218.28,
        "duration": 2.3
    },
    {
        "text": ">> That's awesome.",
        "start": 220.58,
        "duration": 2.325
    },
    {
        "text": "Yeah, that's amazing.",
        "start": 222.905,
        "duration": 2.37
    },
    {
        "text": "If you're building like LLM-inspired apps,",
        "start": 225.275,
        "duration": 3.685
    },
    {
        "text": "you're using Azure AI Search it's very",
        "start": 228.96,
        "duration": 2.56
    },
    {
        "text": "economical to do",
        "start": 231.52,
        "duration": 1.66
    },
    {
        "text": "the retrieval augmented generation pattern with this new model.",
        "start": 233.18,
        "duration": 3.05
    },
    {
        "text": ">> Oh, 100 percent.",
        "start": 236.23,
        "duration": 1.4
    },
    {
        "text": "I had a black blog post",
        "start": 237.63,
        "duration": 3.19
    },
    {
        "text": "that Liam I think talked about earlier on the AI show that",
        "start": 240.82,
        "duration": 3.1
    },
    {
        "text": "actually showed how much better semantic re-ranking",
        "start": 243.92,
        "duration": 3.045
    },
    {
        "text": "is with hybrid search and so now with this new business model,",
        "start": 246.965,
        "duration": 3.835
    },
    {
        "text": "you could use it for all your rag scenarios",
        "start": 250.8,
        "duration": 2.36
    },
    {
        "text": "anytime you interact with",
        "start": 253.16,
        "duration": 1.36
    },
    {
        "text": "Azure AI Search and grand your data to",
        "start": 254.52,
        "duration": 1.94
    },
    {
        "text": "an LLM so really excited about this one.",
        "start": 256.46,
        "duration": 2.405
    },
    {
        "text": ">> Awesome. What's next?",
        "start": 258.865,
        "duration": 1.665
    },
    {
        "text": "I know there was some feature.",
        "start": 260.53,
        "duration": 1.78
    },
    {
        "text": "Yeah, this is the thing that I want to ask you about",
        "start": 262.31,
        "duration": 2.56
    },
    {
        "text": "because Integrated Vectorization sounds interesting,",
        "start": 264.87,
        "duration": 2.86
    },
    {
        "text": "but can you help us explain what it does?",
        "start": 267.73,
        "duration": 1.995
    },
    {
        "text": ">> Yeah, so Integrated Vectorization is really just about",
        "start": 269.725,
        "duration": 4.125
    },
    {
        "text": "end-to-end processing for your generative AI",
        "start": 273.85,
        "duration": 3.28
    },
    {
        "text": "or really just building the rag pattern.",
        "start": 277.13,
        "duration": 2.23
    },
    {
        "text": "In Azure search, previously during",
        "start": 279.36,
        "duration": 2.79
    },
    {
        "text": "our preview of vector search, it was really manual.",
        "start": 282.15,
        "duration": 3.18
    },
    {
        "text": "A lot of times if you add,",
        "start": 285.33,
        "duration": 1.56
    },
    {
        "text": "a bunch of long PDFs,",
        "start": 286.89,
        "duration": 1.32
    },
    {
        "text": "a lot of long documents,",
        "start": 288.21,
        "duration": 1.28
    },
    {
        "text": "you had to manually chunk it maybe you",
        "start": 289.49,
        "duration": 3.2
    },
    {
        "text": "adjust the sentence overlap window is a very manual process.",
        "start": 292.69,
        "duration": 4.18
    },
    {
        "text": "A lot of customers loved using Azure I",
        "start": 296.87,
        "duration": 4.5
    },
    {
        "text": "Search and we have a capability called",
        "start": 301.37,
        "duration": 2.1
    },
    {
        "text": "the Indexer and AI enrichment and skills.",
        "start": 303.47,
        "duration": 2.69
    },
    {
        "text": "A lot of them wanted to say,",
        "start": 306.16,
        "duration": 1.79
    },
    {
        "text": "hey, this is just going to be amazing.",
        "start": 307.95,
        "duration": 2.34
    },
    {
        "text": "If we could just have a built-in skill that'll",
        "start": 310.29,
        "duration": 2.5
    },
    {
        "text": "automatically chunk these documents and then not only that,",
        "start": 312.79,
        "duration": 3.06
    },
    {
        "text": "but are probably my personal favorite embedding model,",
        "start": 315.85,
        "duration": 3.14
    },
    {
        "text": "the Azure Open AI Embedding Model.",
        "start": 318.99,
        "duration": 1.66
    },
    {
        "text": "If we could just automatically send those chunks within",
        "start": 320.65,
        "duration": 2.78
    },
    {
        "text": "the enrichment process in Azure AI search get",
        "start": 323.43,
        "duration": 3.63
    },
    {
        "text": "those vector representations of",
        "start": 327.06,
        "duration": 2.63
    },
    {
        "text": "your data for your chunks and",
        "start": 329.69,
        "duration": 1.58
    },
    {
        "text": "then just automatically throw them into",
        "start": 331.27,
        "duration": 1.82
    },
    {
        "text": "your search index fields and then go crazy quoin",
        "start": 333.09,
        "duration": 2.86
    },
    {
        "text": "and so that's exactly what Integrated Vectorization is it.",
        "start": 335.95,
        "duration": 3.5
    },
    {
        "text": ">> This is really cool.",
        "start": 339.45,
        "duration": 1.23
    },
    {
        "text": ">> Yeah.",
        "start": 340.68,
        "duration": 0.975
    },
    {
        "text": ">> [inaudible] Because I build some samples, you know,",
        "start": 341.655,
        "duration": 3.275
    },
    {
        "text": "with the prompt flow that uses",
        "start": 344.93,
        "duration": 1.5
    },
    {
        "text": "Azure AI search all the time but I had to",
        "start": 346.43,
        "duration": 3.0
    },
    {
        "text": "write my own script and it's not the funniest of code to write.",
        "start": 349.43,
        "duration": 4.82
    },
    {
        "text": "Just like, okay, what's the overlap window on the paragraphs?",
        "start": 354.25,
        "duration": 3.84
    },
    {
        "text": "How much text should I put?",
        "start": 358.09,
        "duration": 1.52
    },
    {
        "text": "You're saying that now there's",
        "start": 359.61,
        "duration": 1.46
    },
    {
        "text": "a new way to do this all in an integrated way.",
        "start": 361.07,
        "duration": 2.8
    },
    {
        "text": ">> Yeah, it's all, you just set",
        "start": 363.87,
        "duration": 1.66
    },
    {
        "text": "it up one time when you're setting",
        "start": 365.53,
        "duration": 1.48
    },
    {
        "text": "up your indexer and which skills you want to use,",
        "start": 367.01,
        "duration": 3.34
    },
    {
        "text": "which we have a split skill for",
        "start": 370.35,
        "duration": 1.74
    },
    {
        "text": "Chunking and Azure opening eye",
        "start": 372.09,
        "duration": 2.26
    },
    {
        "text": "embedding skill as well as",
        "start": 374.35,
        "duration": 1.28
    },
    {
        "text": "a custom embedding skill if you want to use",
        "start": 375.63,
        "duration": 1.86
    },
    {
        "text": "your own custom embedding model and",
        "start": 377.49,
        "duration": 2.08
    },
    {
        "text": "then once you set that up one time you're done you can",
        "start": 379.57,
        "duration": 2.28
    },
    {
        "text": "schedule your indexer to grab",
        "start": 381.85,
        "duration": 2.28
    },
    {
        "text": "your documents from your Azure data source like Blob storage,",
        "start": 384.13,
        "duration": 2.72
    },
    {
        "text": "SQL Cosmos, whatever it may be and then you're done.",
        "start": 386.85,
        "duration": 3.12
    },
    {
        "text": "It's hands off and you have your rack solution just work for you.",
        "start": 389.97,
        "duration": 3.26
    },
    {
        "text": ">> That is impressive.",
        "start": 393.23,
        "duration": 2.435
    },
    {
        "text": "What else do you have to show us?",
        "start": 395.665,
        "duration": 2.085
    },
    {
        "text": ">> I do have a demo that I think",
        "start": 397.75,
        "duration": 2.32
    },
    {
        "text": "is going to be really interesting.",
        "start": 400.07,
        "duration": 2.465
    },
    {
        "text": "Inside of our Azure search vector samples,",
        "start": 402.535,
        "duration": 3.755
    },
    {
        "text": "we have a bunch of different code samples here.",
        "start": 406.29,
        "duration": 2.73
    },
    {
        "text": "Everyone nowadays is a Python guy,",
        "start": 409.02,
        "duration": 2.24
    },
    {
        "text": "so I'm going to show a Python code sample.",
        "start": 411.26,
        "duration": 2.94
    },
    {
        "text": "As you can see here, all I'm doing is importing",
        "start": 414.2,
        "duration": 3.06
    },
    {
        "text": "our Azure search documents library with",
        "start": 417.26,
        "duration": 1.84
    },
    {
        "text": "our latest pre-release version.",
        "start": 419.1,
        "duration": 2.385
    },
    {
        "text": "Importing Open AI Azure Storage Blob.",
        "start": 421.485,
        "duration": 2.875
    },
    {
        "text": "Because I have some documents I want to store in Blob storage.",
        "start": 424.36,
        "duration": 3.28
    },
    {
        "text": "Over here I'm just going to briefly skim through this part just",
        "start": 427.64,
        "duration": 3.19
    },
    {
        "text": "a bunch of libraries I need from Azure search documents.",
        "start": 430.83,
        "duration": 3.41
    },
    {
        "text": "I configured some environment variables here from",
        "start": 434.24,
        "duration": 2.54
    },
    {
        "text": "my Azure AI search service as well my Blob connection string.",
        "start": 436.78,
        "duration": 5.84
    },
    {
        "text": "Over here what I'm going to do is",
        "start": 442.62,
        "duration": 1.62
    },
    {
        "text": "I'm just going to connect to Blob storage.",
        "start": 444.24,
        "duration": 1.77
    },
    {
        "text": "All I did is inside of",
        "start": 446.01,
        "duration": 1.11
    },
    {
        "text": "this documents folder, in my Blob container,",
        "start": 447.12,
        "duration": 1.88
    },
    {
        "text": "I think I put like about five or six PDFs",
        "start": 449.0,
        "duration": 2.59
    },
    {
        "text": "I actually want to do vector search retrieval over.",
        "start": 451.59,
        "duration": 2.745
    },
    {
        "text": ">> Question because people are going to ask this,",
        "start": 454.335,
        "duration": 2.195
    },
    {
        "text": "is this is available in multiple languages, is that right?",
        "start": 456.53,
        "duration": 3.58
    },
    {
        "text": "What languages are available with this [inaudible]?",
        "start": 460.11,
        "duration": 2.73
    },
    {
        "text": ">> Yeah, Azure AI search is available in Python,",
        "start": 462.84,
        "duration": 3.63
    },
    {
        "text": "Dotnet, Java and JavaScript type.",
        "start": 466.47,
        "duration": 3.035
    },
    {
        "text": "Cool. Because I know everyone's going to be like,",
        "start": 469.505,
        "duration": 2.325
    },
    {
        "text": "well, can I do this in my language?",
        "start": 471.83,
        "duration": 1.38
    },
    {
        "text": "Yes, you probably can. I'm sorry, I keep going.",
        "start": 473.21,
        "duration": 2.64
    },
    {
        "text": ">> You're good. Happy to show.",
        "start": 475.85,
        "duration": 2.545
    },
    {
        "text": "Yeah, so then once I connected to",
        "start": 478.395,
        "duration": 2.175
    },
    {
        "text": "my Blob storage inside of this super notebook,",
        "start": 480.57,
        "duration": 2.22
    },
    {
        "text": "now I want to create a data source inside of Azure AI search.",
        "start": 482.79,
        "duration": 3.73
    },
    {
        "text": "All I could do here is if you follow this code block,",
        "start": 486.52,
        "duration": 3.43
    },
    {
        "text": "just use this search indexer,",
        "start": 489.95,
        "duration": 1.7
    },
    {
        "text": "data container and data source connection method.",
        "start": 491.65,
        "duration": 3.01
    },
    {
        "text": "I'm passing in my blob connection string",
        "start": 494.66,
        "duration": 3.31
    },
    {
        "text": "in my container name and then boom,",
        "start": 497.97,
        "duration": 1.94
    },
    {
        "text": "I get Azure search Integrated Vectorization sample Blob,",
        "start": 499.91,
        "duration": 3.06
    },
    {
        "text": "which is probably a really long name for a blob data source.",
        "start": 502.97,
        "duration": 3.08
    },
    {
        "text": "But that's okay. Then once I have that.",
        "start": 506.05,
        "duration": 2.765
    },
    {
        "text": ">> If I could pause right here. Effectively you're",
        "start": 508.815,
        "duration": 2.995
    },
    {
        "text": "telling Azure AI search,",
        "start": 511.81,
        "duration": 1.58
    },
    {
        "text": "Hey, my data lives over here,",
        "start": 513.39,
        "duration": 2.195
    },
    {
        "text": "and here's a connection to it.",
        "start": 515.585,
        "duration": 1.375
    },
    {
        "text": "That's persistent in Azure AI search, is that right?",
        "start": 516.96,
        "duration": 2.625
    },
    {
        "text": ">> Hundred percent.",
        "start": 519.585,
        "duration": 1.5
    },
    {
        "text": ">> This is much better. Sorry, I'm",
        "start": 521.085,
        "duration": 2.245
    },
    {
        "text": "going to put myself on the screen here.",
        "start": 523.33,
        "duration": 2.97
    },
    {
        "text": "Just because I make the index 1 time with the vector,",
        "start": 529.01,
        "duration": 4.0
    },
    {
        "text": "with my goofy code that I",
        "start": 533.01,
        "duration": 1.58
    },
    {
        "text": "use for whatever Contoso outdoors company,",
        "start": 534.59,
        "duration": 2.18
    },
    {
        "text": "that doesn't mean that it's going to continue to be updated.",
        "start": 536.77,
        "duration": 2.7
    },
    {
        "text": "Is this a situation that makes",
        "start": 539.47,
        "duration": 2.0
    },
    {
        "text": "it so that this can continue to be updated?",
        "start": 541.47,
        "duration": 2.385
    },
    {
        "text": ">> Correct.",
        "start": 543.855,
        "duration": 1.455
    },
    {
        "text": ">> You said it so fast.",
        "start": 545.31,
        "duration": 2.52
    },
    {
        "text": "I thought you were going to be like yes,",
        "start": 547.83,
        "duration": 2.655
    },
    {
        "text": "you can upload documents whenever you want to",
        "start": 550.485,
        "duration": 2.085
    },
    {
        "text": "blob storage and it will pick it up, is that right?",
        "start": 552.57,
        "duration": 2.505
    },
    {
        "text": ">> 100 percent, that's all right now.",
        "start": 555.075,
        "duration": 2.385
    },
    {
        "text": ">> Let's keep going.",
        "start": 557.46,
        "duration": 1.395
    },
    {
        "text": ">> Cool. Now that I connected",
        "start": 558.855,
        "duration": 2.265
    },
    {
        "text": "my data source Azure AI",
        "start": 561.12,
        "duration": 1.59
    },
    {
        "text": "search in this case Blob you can do Cosmos,",
        "start": 562.71,
        "duration": 2.175
    },
    {
        "text": "you can do SQL, ADLS, whatever you want.",
        "start": 564.885,
        "duration": 2.58
    },
    {
        "text": "Now I'm just going to create my search index.",
        "start": 567.465,
        "duration": 2.52
    },
    {
        "text": "This part stays standard with creating any Azure AI Search index.",
        "start": 569.985,
        "duration": 4.755
    },
    {
        "text": "My schema relatively simple parent ID because I want to",
        "start": 574.74,
        "duration": 3.0
    },
    {
        "text": "keep the parent document at least IDs,",
        "start": 577.74,
        "duration": 2.955
    },
    {
        "text": "title because I want to maybe display the title of",
        "start": 580.695,
        "duration": 2.235
    },
    {
        "text": "my PDF actually in my UI,",
        "start": 582.93,
        "duration": 3.3
    },
    {
        "text": "in my rack solution chunk ID, chunk and vector.",
        "start": 586.23,
        "duration": 4.05
    },
    {
        "text": "These are probably the real important ones",
        "start": 590.28,
        "duration": 1.86
    },
    {
        "text": "that is actually going to be",
        "start": 592.14,
        "duration": 1.65
    },
    {
        "text": "used by a skill set that I'm going to show later.",
        "start": 593.79,
        "duration": 3.9
    },
    {
        "text": ">> Because I want to make sure sometimes people",
        "start": 597.69,
        "duration": 2.22
    },
    {
        "text": "lose at least I lost the story in this.",
        "start": 599.91,
        "duration": 3.225
    },
    {
        "text": "Effectively, this is like a paragraph of",
        "start": 603.135,
        "duration": 2.595
    },
    {
        "text": "text from your documents your PDF might be 10,000 pages long.",
        "start": 605.73,
        "duration": 4.47
    },
    {
        "text": "This is just a single chunk,",
        "start": 610.2,
        "duration": 2.67
    },
    {
        "text": "and the parent ID is referencing.",
        "start": 612.87,
        "duration": 2.565
    },
    {
        "text": "This is the PDF,",
        "start": 615.435,
        "duration": 1.755
    },
    {
        "text": "this is the chunk number.",
        "start": 617.19,
        "duration": 2.025
    },
    {
        "text": "This is the title of the thing, is this right?",
        "start": 619.215,
        "duration": 3.18
    },
    {
        "text": ">> Yeah, 100 percent that's exactly right.",
        "start": 622.395,
        "duration": 2.625
    },
    {
        "text": ">> Yeah. One of the things that I tell people about this is",
        "start": 625.02,
        "duration": 2.445
    },
    {
        "text": "this is super useful specifically",
        "start": 627.465,
        "duration": 2.775
    },
    {
        "text": "when you want to economize the stuff that you put",
        "start": 630.24,
        "duration": 2.505
    },
    {
        "text": "into a prompt for retrieval augmented generation,",
        "start": 632.745,
        "duration": 2.88
    },
    {
        "text": "because if you overspill the prompt,",
        "start": 635.625,
        "duration": 1.875
    },
    {
        "text": "it's not going to tell you",
        "start": 637.5,
        "duration": 0.72
    },
    {
        "text": "anything it's just going to be really wrong.",
        "start": 638.22,
        "duration": 1.59
    },
    {
        "text": ">> Yeah, that's precisely right.",
        "start": 639.81,
        "duration": 2.4
    },
    {
        "text": ">> Awesome.",
        "start": 642.21,
        "duration": 1.23
    },
    {
        "text": ">> Cool. Moving forward at this part I'm not going to",
        "start": 643.44,
        "duration": 2.7
    },
    {
        "text": "spend too much time on because I",
        "start": 646.14,
        "duration": 1.11
    },
    {
        "text": "think you've seen it a lot of times.",
        "start": 647.25,
        "duration": 1.2
    },
    {
        "text": "This is the vector search configuration.",
        "start": 648.45,
        "duration": 2.58
    },
    {
        "text": "Over here.\\ I just configured a couple but I'm only going to use",
        "start": 651.03,
        "duration": 4.38
    },
    {
        "text": "my HMSW vector index on",
        "start": 655.41,
        "duration": 2.73
    },
    {
        "text": "my vector field property that I configured over here in my schema.",
        "start": 658.14,
        "duration": 5.535
    },
    {
        "text": "Then I also have this thing called vectorizer.",
        "start": 663.675,
        "duration": 2.97
    },
    {
        "text": "This is new, this is",
        "start": 666.645,
        "duration": 1.245
    },
    {
        "text": "another cool feature that's part of the integrated vectorization.",
        "start": 667.89,
        "duration": 2.805
    },
    {
        "text": "We know that we're going to be doing",
        "start": 670.695,
        "duration": 1.875
    },
    {
        "text": "Azure Open AI Skills which I'm going to",
        "start": 672.57,
        "duration": 1.98
    },
    {
        "text": "show in the next code block.",
        "start": 674.55,
        "duration": 1.845
    },
    {
        "text": "But as part of this vectorizer this",
        "start": 676.395,
        "duration": 2.28
    },
    {
        "text": "allows me to take advantage of query vectorization.",
        "start": 678.675,
        "duration": 2.805
    },
    {
        "text": "Now when I pass in text or image whatever it may be,",
        "start": 681.48,
        "duration": 4.05
    },
    {
        "text": "what it's going to do automatically when I",
        "start": 685.53,
        "duration": 2.13
    },
    {
        "text": "start showing an example of searching documents,",
        "start": 687.66,
        "duration": 2.395
    },
    {
        "text": "it already has my Azure OpenAI configuration over here.",
        "start": 690.055,
        "duration": 3.775
    },
    {
        "text": "I no longer have to use the same function to generate",
        "start": 693.83,
        "duration": 3.54
    },
    {
        "text": "a query vector then pass it back",
        "start": 697.37,
        "duration": 2.28
    },
    {
        "text": "to Azure AI Search it'll just handle it for me.",
        "start": 699.65,
        "duration": 3.09
    },
    {
        "text": "Pretty convenient as well.",
        "start": 702.74,
        "duration": 1.695
    },
    {
        "text": ">> Nice.",
        "start": 704.435,
        "duration": 1.185
    },
    {
        "text": ">> Then real quick my semantic can figure over",
        "start": 705.62,
        "duration": 3.03
    },
    {
        "text": "here because I want to take advantage of that semantic ranker.",
        "start": 708.65,
        "duration": 2.79
    },
    {
        "text": "That's the only prerequisite for that.",
        "start": 711.44,
        "duration": 2.105
    },
    {
        "text": "Then this is the cool part,",
        "start": 713.545,
        "duration": 2.555
    },
    {
        "text": "the new part, so creating a skill set.",
        "start": 716.1,
        "duration": 1.995
    },
    {
        "text": "An Azure AI Search has a bunch of skills,",
        "start": 718.095,
        "duration": 2.07
    },
    {
        "text": "what I'm going to do first is use the split skill.",
        "start": 720.165,
        "duration": 2.775
    },
    {
        "text": "The split skill as it says in",
        "start": 722.94,
        "duration": 2.19
    },
    {
        "text": "my description here split skill to chunk the documents.",
        "start": 725.13,
        "duration": 2.73
    },
    {
        "text": "What I want to do is I go ahead and look at",
        "start": 727.86,
        "duration": 3.06
    },
    {
        "text": "the documentation for what",
        "start": 730.92,
        "duration": 1.215
    },
    {
        "text": "the split skill contract requires In Azure AI search.",
        "start": 732.135,
        "duration": 3.615
    },
    {
        "text": "I'm just going to go ahead and really just pay attention to",
        "start": 735.75,
        "duration": 3.06
    },
    {
        "text": "these two properties since these are the ones",
        "start": 738.81,
        "duration": 1.71
    },
    {
        "text": "that you probably want to care about.",
        "start": 740.52,
        "duration": 2.4
    },
    {
        "text": "Text split mode pages,",
        "start": 742.92,
        "duration": 1.92
    },
    {
        "text": "that means I want to split by page.",
        "start": 744.84,
        "duration": 2.475
    },
    {
        "text": "But what these two parameters mean over",
        "start": 747.315,
        "duration": 2.835
    },
    {
        "text": "here maximum page length, 2048.",
        "start": 750.15,
        "duration": 2.715
    },
    {
        "text": "This unit is in characters of text.",
        "start": 752.865,
        "duration": 2.895
    },
    {
        "text": "This means that every 2048 characters inside of",
        "start": 755.76,
        "duration": 3.21
    },
    {
        "text": "the PDF that I haven't blow up split,",
        "start": 758.97,
        "duration": 2.97
    },
    {
        "text": "I'm considering that a chunk.",
        "start": 761.94,
        "duration": 1.44
    },
    {
        "text": "Then this other parameter page overlap length like we talked about",
        "start": 763.38,
        "duration": 3.0
    },
    {
        "text": "earlier That's the sentence overlap in characters unit as well,",
        "start": 766.38,
        "duration": 4.02
    },
    {
        "text": "so 20 characters before,",
        "start": 770.4,
        "duration": 1.71
    },
    {
        "text": "20 characters after each chunk.",
        "start": 772.11,
        "duration": 2.49
    },
    {
        "text": "Then lastly, just doing input and output to output to",
        "start": 774.6,
        "duration": 4.23
    },
    {
        "text": "the pages field inside",
        "start": 778.83,
        "duration": 2.94
    },
    {
        "text": "of the cognitive search index through the skill set pipeline.",
        "start": 781.77,
        "duration": 3.57
    },
    {
        "text": "Then from here now I'm just doing some field mapping.",
        "start": 785.34,
        "duration": 2.67
    },
    {
        "text": "Now that I have my chunks inside of this pages,",
        "start": 788.01,
        "duration": 3.285
    },
    {
        "text": "what I want to do is I want to go",
        "start": 791.295,
        "duration": 1.485
    },
    {
        "text": "inside all of these pages and then",
        "start": 792.78,
        "duration": 1.86
    },
    {
        "text": "generate and pass these chunks",
        "start": 794.64,
        "duration": 2.31
    },
    {
        "text": "into my Azure OpenAI embedding skill.",
        "start": 796.95,
        "duration": 2.07
    },
    {
        "text": "Then I'm returning back the embedding from",
        "start": 799.02,
        "duration": 3.3
    },
    {
        "text": "the response that I get back from",
        "start": 802.32,
        "duration": 1.94
    },
    {
        "text": "Azure OpenAI embedding 8002 model.",
        "start": 804.26,
        "duration": 2.73
    },
    {
        "text": "Then I'm mapping it to the vector field that I",
        "start": 806.99,
        "duration": 2.19
    },
    {
        "text": "defined in my Azure AI Search index.",
        "start": 809.18,
        "duration": 3.735
    },
    {
        "text": ">> Can I interrupt just one second.",
        "start": 812.915,
        "duration": 2.325
    },
    {
        "text": "This is important because first when I saw",
        "start": 815.24,
        "duration": 2.535
    },
    {
        "text": "2048 I was like is that the number of tokens?",
        "start": 817.775,
        "duration": 2.685
    },
    {
        "text": "But no, this is the number of characters with",
        "start": 820.46,
        "duration": 2.35
    },
    {
        "text": "a 20 character overlap and you can totally change that yourself.",
        "start": 822.81,
        "duration": 4.59
    },
    {
        "text": "The second question I have are",
        "start": 827.4,
        "duration": 1.29
    },
    {
        "text": "these skills now part of Azure AI Search?",
        "start": 828.69,
        "duration": 3.975
    },
    {
        "text": "Because I know you can build your own custom skills,",
        "start": 832.665,
        "duration": 2.37
    },
    {
        "text": "but these are actually part of",
        "start": 835.035,
        "duration": 1.515
    },
    {
        "text": "Azure AI Search now. Is that correct?",
        "start": 836.55,
        "duration": 2.085
    },
    {
        "text": ">> Yeah, this split skill actually existed for a long time",
        "start": 838.635,
        "duration": 4.02
    },
    {
        "text": "we just made some updates to it to",
        "start": 842.655,
        "duration": 1.8
    },
    {
        "text": "cater for more chunk like scenarios.",
        "start": 844.455,
        "duration": 2.52
    },
    {
        "text": ">> Makes sense. Another thing that",
        "start": 846.975,
        "duration": 2.76
    },
    {
        "text": "may be confusing to some people I know it was to me initially,",
        "start": 849.735,
        "duration": 3.465
    },
    {
        "text": "these skills you define once and then you can reuse",
        "start": 853.2,
        "duration": 3.9
    },
    {
        "text": "them for an index over time is that right?",
        "start": 857.1,
        "duration": 3.96
    },
    {
        "text": ">> Yeah, exactly.",
        "start": 861.06,
        "duration": 2.07
    },
    {
        "text": ">> Keep showing I'm sorry about that.",
        "start": 863.13,
        "duration": 2.475
    },
    {
        "text": ">> Cool. No worries.",
        "start": 865.605,
        "duration": 2.19
    },
    {
        "text": "Pretty much almost done, then we can",
        "start": 867.795,
        "duration": 2.115
    },
    {
        "text": "get to actually querying the index.",
        "start": 869.91,
        "duration": 1.695
    },
    {
        "text": "This index projections, all this really is,",
        "start": 871.605,
        "duration": 3.925
    },
    {
        "text": "once the skill set chunks",
        "start": 876.62,
        "duration": 3.16
    },
    {
        "text": "your documents and generates the vectors.",
        "start": 879.78,
        "duration": 2.1
    },
    {
        "text": "Some customers like having their chunks",
        "start": 881.88,
        "duration": 1.98
    },
    {
        "text": "in a separate AI Search index",
        "start": 883.86,
        "duration": 1.8
    },
    {
        "text": "and some like having maybe with",
        "start": 885.66,
        "duration": 1.74
    },
    {
        "text": "their parent documents or parent ID's.",
        "start": 887.4,
        "duration": 2.07
    },
    {
        "text": "That's all this index projections code is really doing.",
        "start": 889.47,
        "duration": 3.96
    },
    {
        "text": "It's pretty much just getting the output from my previous step in",
        "start": 893.43,
        "duration": 4.8
    },
    {
        "text": "my skill set process which was",
        "start": 898.23,
        "duration": 1.35
    },
    {
        "text": "the Azure OpenAI Embedding skill",
        "start": 899.58,
        "duration": 1.725
    },
    {
        "text": "now just mapping it to the different fields.",
        "start": 901.305,
        "duration": 2.79
    },
    {
        "text": "This from pages over here is coming over here to my actual chunks.",
        "start": 904.095,
        "duration": 4.485
    },
    {
        "text": "These are the actual chunks of text.",
        "start": 908.58,
        "duration": 4.275
    },
    {
        "text": "Then vector over here is the actual vector field,",
        "start": 912.855,
        "duration": 3.885
    },
    {
        "text": "the 1536 dimensions of floating points.",
        "start": 916.74,
        "duration": 5.865
    },
    {
        "text": ">> Then over here I'm getting actually from Blob storage,",
        "start": 922.605,
        "duration": 2.805
    },
    {
        "text": "I want to keep the title so I'm just doing a field map from",
        "start": 925.41,
        "duration": 3.12
    },
    {
        "text": "my Blob storage metadata field",
        "start": 928.53,
        "duration": 1.8
    },
    {
        "text": "just so I can display the title as well.",
        "start": 930.33,
        "duration": 2.055
    },
    {
        "text": ">> This is just like a way of aggregating all of the data that",
        "start": 932.385,
        "duration": 3.15
    },
    {
        "text": "all the skills generated into put this into this field,",
        "start": 935.535,
        "duration": 3.45
    },
    {
        "text": "this is into that field. This is cool.",
        "start": 938.985,
        "duration": 1.665
    },
    {
        "text": ">> Yeah, precisely.",
        "start": 940.65,
        "duration": 1.59
    },
    {
        "text": "That's it then all I have to do is create my indexer.",
        "start": 942.24,
        "duration": 2.775
    },
    {
        "text": "This part it's pretty cool because this is where you",
        "start": 945.015,
        "duration": 1.875
    },
    {
        "text": "can have like a schedule.",
        "start": 946.89,
        "duration": 3.03
    },
    {
        "text": "You could have your indexer run like on a weekly basis,",
        "start": 949.92,
        "duration": 3.96
    },
    {
        "text": "on a daily basis.",
        "start": 953.88,
        "duration": 1.23
    },
    {
        "text": "If you're constantly moving data inside my Blob storage container,",
        "start": 955.11,
        "duration": 3.99
    },
    {
        "text": "it'll automatically run execute",
        "start": 959.1,
        "duration": 1.86
    },
    {
        "text": "these skills the chunking",
        "start": 960.96,
        "duration": 1.65
    },
    {
        "text": "and the vectorization that I just defined.",
        "start": 962.61,
        "duration": 2.265
    },
    {
        "text": "It's automatically going to be mapped to my AI Search index.",
        "start": 964.875,
        "duration": 4.545
    },
    {
        "text": ">> This is question about that in terms of economy,",
        "start": 969.42,
        "duration": 2.625
    },
    {
        "text": "dos it remember things it's already indexed?",
        "start": 972.045,
        "duration": 3.27
    },
    {
        "text": ">> Yes, it does.",
        "start": 975.315,
        "duration": 2.04
    },
    {
        "text": ">> That's cool. I was wondering that because",
        "start": 977.355,
        "duration": 3.855
    },
    {
        "text": "generally if you delete",
        "start": 981.21,
        "duration": 1.89
    },
    {
        "text": "something it means it doesn't have to do anything.",
        "start": 983.1,
        "duration": 2.835
    },
    {
        "text": "But if you update something,",
        "start": 985.935,
        "duration": 1.815
    },
    {
        "text": "it does have to do something or if you add something.",
        "start": 987.75,
        "duration": 2.07
    },
    {
        "text": "But if you leave something there you don't want to spend",
        "start": 989.82,
        "duration": 2.58
    },
    {
        "text": "the tokens through eight to two if you're",
        "start": 992.4,
        "duration": 1.59
    },
    {
        "text": "doing the embeddings and that will take care of it.",
        "start": 993.99,
        "duration": 1.83
    },
    {
        "text": ">> Yeah, for sure if",
        "start": 995.82,
        "duration": 2.61
    },
    {
        "text": "you already spend like a bunch of money factorizing things",
        "start": 998.43,
        "duration": 2.43
    },
    {
        "text": "and it's a duplicate the index is smart",
        "start": 1000.86,
        "duration": 2.46
    },
    {
        "text": "enough to detect that, yeah, you're good to go.",
        "start": 1003.32,
        "duration": 3.705
    },
    {
        "text": ">> I love it.",
        "start": 1007.025,
        "duration": 0.735
    },
    {
        "text": ">> Cool. Once I created my indexer,",
        "start": 1007.76,
        "duration": 2.88
    },
    {
        "text": "I wait I think it was about a minute or",
        "start": 1010.64,
        "duration": 2.205
    },
    {
        "text": "two then it goes ahead does the chunking,",
        "start": 1012.845,
        "duration": 2.805
    },
    {
        "text": "does the vectorization grabs my PDSM blob,",
        "start": 1015.65,
        "duration": 2.625
    },
    {
        "text": "now I can start doing some queries.",
        "start": 1018.275,
        "duration": 2.115
    },
    {
        "text": "This is pretty much the pure vector similarity search,",
        "start": 1020.39,
        "duration": 3.495
    },
    {
        "text": "you can see over here I have a query which is more comprehensive,",
        "start": 1023.885,
        "duration": 2.745
    },
    {
        "text": "North Wind health plus versus North Wind standard.",
        "start": 1026.63,
        "duration": 2.685
    },
    {
        "text": "Over here is my vector essentially my request body,",
        "start": 1029.315,
        "duration": 4.215
    },
    {
        "text": "I have a vectorizable text query.",
        "start": 1033.53,
        "duration": 2.58
    },
    {
        "text": "I'm just going to pass in the pure text.",
        "start": 1036.11,
        "duration": 1.98
    },
    {
        "text": "It's going to my vectorizer that I defined earlier.",
        "start": 1038.09,
        "duration": 2.94
    },
    {
        "text": "I'm just going to say, hey, K = 1 Just give me one chunk back.",
        "start": 1041.03,
        "duration": 3.63
    },
    {
        "text": "Do it over my vector field.",
        "start": 1044.66,
        "duration": 1.905
    },
    {
        "text": "I also have this field exhaustive equals true.",
        "start": 1046.565,
        "duration": 2.685
    },
    {
        "text": "Just because I want to find",
        "start": 1049.25,
        "duration": 1.8
    },
    {
        "text": "like 100 percent recall of the ground truth value.",
        "start": 1051.05,
        "duration": 2.46
    },
    {
        "text": "But if you want you could turn",
        "start": 1053.51,
        "duration": 2.91
    },
    {
        "text": "that to false and just do a ANN search as well.",
        "start": 1056.42,
        "duration": 3.54
    },
    {
        "text": "Here I go, I get my cosine similarity score,",
        "start": 1059.96,
        "duration": 2.895
    },
    {
        "text": "I get my content and it tells me exactly North",
        "start": 1062.855,
        "duration": 2.67
    },
    {
        "text": "Health Plus offers more",
        "start": 1065.525,
        "duration": 1.155
    },
    {
        "text": "comprehensive coverage than North Health Standard,",
        "start": 1066.68,
        "duration": 1.995
    },
    {
        "text": "which some additional information from my chunk. That's it.",
        "start": 1068.675,
        "duration": 3.24
    },
    {
        "text": ">> This is amazing",
        "start": 1071.915,
        "duration": 2.445
    },
    {
        "text": "because just from the search alone I'm getting really good answers",
        "start": 1074.36,
        "duration": 3.765
    },
    {
        "text": "imagine if you put that into a language model to generate",
        "start": 1078.125,
        "duration": 3.48
    },
    {
        "text": "even more customized responses because I've",
        "start": 1081.605,
        "duration": 3.165
    },
    {
        "text": "always told people you stop using LLMs like databases,",
        "start": 1084.77,
        "duration": 3.315
    },
    {
        "text": "use them like language calculators use Azure AI Search as",
        "start": 1088.085,
        "duration": 3.795
    },
    {
        "text": "your database and then put those chunks into your search request.",
        "start": 1091.88,
        "duration": 5.38
    },
    {
        "text": "This is amazing my friend.",
        "start": 1097.26,
        "duration": 1.64
    },
    {
        "text": "Where can people go to find out more about this stuff?",
        "start": 1098.9,
        "duration": 2.545
    },
    {
        "text": ">> Yeah, precisely. You can honestly visit all",
        "start": 1101.445,
        "duration": 3.275
    },
    {
        "text": "of these resources by visiting our block post.",
        "start": 1104.72,
        "duration": 3.305
    },
    {
        "text": "We announced at Microsoft",
        "start": 1108.025,
        "duration": 2.115
    },
    {
        "text": "ignite the general availability of vector search GA,",
        "start": 1110.14,
        "duration": 3.265
    },
    {
        "text": "semantic ranker as well as a hint to",
        "start": 1113.405,
        "duration": 2.855
    },
    {
        "text": "the integrated vectorization feature that I just showed today.",
        "start": 1116.26,
        "duration": 3.76
    },
    {
        "text": "I recommend visiting our block post at aka.ms/AISearchIgnite2023",
        "start": 1120.02,
        "duration": 6.99
    },
    {
        "text": ">> Right here. I put it up on the screen for you, there you go.",
        "start": 1127.01,
        "duration": 4.84
    },
    {
        "text": "By the way, this is absolutely amazing.",
        "start": 1131.85,
        "duration": 3.81
    },
    {
        "text": "It's something that I've been",
        "start": 1135.66,
        "duration": 1.56
    },
    {
        "text": "struggling to know how do I set this up?",
        "start": 1137.22,
        "duration": 2.46
    },
    {
        "text": "Because anytime I do these samples",
        "start": 1139.68,
        "duration": 1.7
    },
    {
        "text": "particularly with retrievable augmented generation,",
        "start": 1141.38,
        "duration": 2.26
    },
    {
        "text": "I'm doing the chunking stuff it's",
        "start": 1143.64,
        "duration": 1.98
    },
    {
        "text": "just like a one time thing for the one sample.",
        "start": 1145.62,
        "duration": 2.14
    },
    {
        "text": "But the reality is this thing needs to be",
        "start": 1147.76,
        "duration": 2.36
    },
    {
        "text": "a living thing and this does it all for you.",
        "start": 1150.12,
        "duration": 3.04
    },
    {
        "text": ">> That's right.",
        "start": 1153.16,
        "duration": 1.11
    },
    {
        "text": ">> Amazing. Thanks so much for being with us my friend.",
        "start": 1154.27,
        "duration": 2.525
    },
    {
        "text": ">> Yeah, no problem I love be here.",
        "start": 1156.795,
        "duration": 2.0
    },
    {
        "text": ">> Awesome. Thank you so much for",
        "start": 1158.795,
        "duration": 1.525
    },
    {
        "text": "watching and learning all about generating",
        "start": 1160.32,
        "duration": 1.94
    },
    {
        "text": "the right answers with Azure AI Search",
        "start": 1162.26,
        "duration": 2.36
    },
    {
        "text": "the new news since Microsoft Ignite.",
        "start": 1164.62,
        "duration": 2.56
    },
    {
        "text": "Thank you so much for watching",
        "start": 1167.18,
        "duration": 1.17
    },
    {
        "text": "hopefully we'll see you next day here.",
        "start": 1168.35,
        "duration": 1.435
    },
    {
        "text": "[MUSIC]",
        "start": 1169.785,
        "duration": 10.878
    }
]